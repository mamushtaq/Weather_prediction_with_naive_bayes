{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9JpVhacFaYf"
      },
      "outputs": [],
      "source": [
        "#Importing all the necessary libraries\n",
        "import pandas as pd #Pandas library to access and change our csv file\n",
        "import numpy as np #numpy to perform necessary calculations\n",
        "import math #math to use pi\n",
        "from sklearn.model_selection import train_test_split #sklearn train test split to split our data in test and train data\n",
        "from sklearn.metrics import accuracy_score#to find the accuracy of our model.\n",
        "\n",
        "#Importing sklearn's naive bayes to check our function by comparing\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing our csv file\n",
        "df = pd.read_csv('/content/Weather Data.csv')"
      ],
      "metadata": {
        "id": "UfrcJxu_yT7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating our own Gaussian Naive Bayes class. This class is designed to work exactly like sklearn library. We will later compare the results as well.\n",
        "class GaussianNaiveBayes():\n",
        "  def __init__(self): #The first function which is automatically run when a new object is created. This will create necessary variables for the class\n",
        "    print(\"Gaussian Naive Baye's Object is created\")\n",
        "    self.mean = []\n",
        "    self.std = []\n",
        "    self.y = []\n",
        "    self.predicted = []\n",
        "  \n",
        "  def fit(self, x_train, y_train): #fit command to train our model using train data. This will find mean and standard deviation of our data which will later be used in gaussian.\n",
        "    self.find_mean_and_std(x_train)\n",
        "    self.y = y_train #saving the y train data to find priori probability later.\n",
        "\n",
        "\n",
        "  def find_mean_and_std(self,data): #this funcion calculates the mean and std of every column and saves it into our class's vairables.\n",
        "    mean = []\n",
        "    std = []\n",
        "    for col in data.columns:\n",
        "      mean.append(data[col].mean())\n",
        "      std.append(data[col].std())\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "  \n",
        "  def predict(self, x_test): #This function will predict the y using given test data. \n",
        "    weather_p = []\n",
        "    self.predicted = []\n",
        "    i = 0\n",
        "    while i < int(len(x_test)):\n",
        "      for weather in self.y.unique():\n",
        "        inputvalues = x_test.iloc[i] # we will be sending every input value for each weather cell and see which weather has the highest probability. \n",
        "        weather_p.append(self.naive_bayes(weather, inputvalues)) #Find posterior probabilities for each weather.\n",
        "      i = i + 1\n",
        "      prediction = self.y.loc[weather_p.index(max(weather_p))]\n",
        "      self.predicted.append(prediction) # The weather with highest probability is stored in predicted array. This array is then returned. \n",
        "      continue\n",
        "    return self.predicted\n",
        "      \n",
        "  def naive_bayes(self, y, input):\n",
        "    #Finding P(y) priori probability\n",
        "    priori = int(self.y.value_counts()[y])/int(len(self.y))\n",
        "    #Finding P(x|y)\n",
        "    likelihood = []\n",
        "    #Find likelihood probability of each column of features and storing them in likelihood list\n",
        "    for i in range(len(self.mean)):\n",
        "      likelihood.append(self.find_likelihood_probability(self.mean[i], self.std[i], input[i]))\n",
        "    #Finding the posterior probability by implementing the equation as derived in theoretical background.\n",
        "    likelihood_product = math.prod(likelihood)\n",
        "    numerator = priori*likelihood_product\n",
        "    denominator = 0\n",
        "    for y1 in self.y:\n",
        "      priori1 = int(self.y.value_counts()[y1])/int(len(self.y))\n",
        "      denominator = denominator + priori1*likelihood_product\n",
        "    return (numerator/denominator)\n",
        "\n",
        "  def find_likelihood_probability(self, m, std, v): #This function will find the likelihood probabilities using gaussian equation.\n",
        "    expo = np.exp(-((float(v)-float(m))**2)/(2*math.pi*float(std)**2))\n",
        "    return (expo/(np.sqrt(2*np.pi*float(std)*float(std))))\n"
      ],
      "metadata": {
        "id": "acDzv6tPxxaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separating x and y train"
      ],
      "metadata": {
        "id": "ghusSp7GIysR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Weather']#Separating the dependent and independent variables.\n",
        "x = df.drop(['Weather', 'Date/Time'], axis=1) #Removing unnecessary columns"
      ],
      "metadata": {
        "id": "IBRRR54WJRZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In this block we are taking a sample from our data to check the model faster.\n",
        "x = x.head(300)\n",
        "y = y.head(300)"
      ],
      "metadata": {
        "id": "9JAX4QEHfz-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using the train test split command to split our data in xtrain, xtest, ytrain and ytest in a ratio of 80/20 \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "exuGoQtlAElm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In this block we will create a model, train it using training data and get a predicted y by inputing test data.\n",
        "model = GaussianNaiveBayes()\n",
        "model.fit(x_train, y_train)\n",
        "predicted_y = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlJlNNy0AcEx",
        "outputId": "00adf820-29b0-4795-9c43-a38e2f47d144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Naive Baye's Object is created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding accurary of our prediction\n",
        "accuracy = accuracy_score(y_test, predicted_y)\n",
        "accuracy = accuracy*100 #converting to percentage"
      ],
      "metadata": {
        "id": "TH_QVPFTfODz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{accuracy}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoWhDJGsfqHr",
        "outputId": "ee1833d8-df78-43d1-88ce-355fc9746e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.333333333333334%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing naive bayes from sklearn library\n",
        "model2 = GaussianNB()\n",
        "model2.fit(x_train, y_train)\n",
        "predictedy2 = model2.predict(x_test)"
      ],
      "metadata": {
        "id": "5tTcuHSn20Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding accuracy of sklearn's prediction\n",
        "accuracy2 = accuracy_score(y_test, predictedy2)\n",
        "accuracy2 = accuracy2*100\n",
        "print(f\"The accuracy of our model is {accuracy} and the accuracy of sklearn's model is {accuracy2}\")\n",
        "#We can see that the accuracy of sklearn's model is higher than ours and it takes less time than our class."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC6g4f7o3ddp",
        "outputId": "7b7348f1-661f-4e1f-b12d-3c5b6d643546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of our model is 13.333333333333334 and the accuracy of sklearn's model is 45.0\n"
          ]
        }
      ]
    }
  ]
}